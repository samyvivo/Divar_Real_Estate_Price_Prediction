import streamlit as st
import pandas as pd
import joblib
import pydeck as pdk


st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Vazirmatn&display=swap');

    html, body, [class*="css"]  {
        font-family: 'Vazirmatn', sans-serif;
    }

    h1, h2, h3, h4, h5, h6, p, div, span {
        font-family: 'Vazirmatn', sans-serif !important;
    }
    </style>
""", unsafe_allow_html=True)

# ===== Load Model & Data =====
model = joblib.load("best_model.pkl")
address_freq = joblib.load("address_freq.pkl")
coords = joblib.load("coords.pkl")  # keys must be English names (same as training)

# ===== English address list (the keys used in model/coords/address_freq) =====
address_list_eng = [
    'Shahran', 'Pardis', 'Shahrake Qods', 'Shahrake Gharb', 'North Program Organization',
    'Andisheh', 'West Ferdows Boulevard', 'Narmak', 'Saadat Abad', 'Zafar', 'Islamshahr',
    'Pirouzi', 'Shahrake Shahid Bagheri', 'Moniriyeh', 'Velenjak', 'Amirieh',
    'Southern Janatabad', 'Salsabil', 'Zargandeh', 'Feiz Garden', 'Water Organization',
    'Unknown', 'ShahrAra', 'Gisha', 'Ray', 'Abbasabad', 'Ostad Moein', 'Farmanieh',
    'Parand', 'Punak', 'Qasr-od-Dasht', 'Aqdasieh', 'Pakdasht', 'Railway', 'Central Janatabad',
    'East Ferdows Boulevard', 'Pakdasht KhatunAbad', 'Sattarkhan', 'Baghestan', 'Shahryar',
    'Northern Janatabad', 'Daryan No', 'Southern Program Organization', 'Rudhen', 'West Pars',
    'Afsarieh', 'Marzdaran', 'Dorous', 'Sadeghieh', 'Chahardangeh', 'Baqershahr', 'Jeyhoon',
    'Lavizan', 'Shams Abad', 'Fatemi', 'Keshavarz Boulevard', 'Kahrizak', 'Qarchak',
    'Northren Jamalzadeh', 'Azarbaijan', 'Bahar', 'Persian Gulf Martyrs Lake', 'Beryanak',
    'Heshmatieh', 'Elm-o-Sanat', 'Golestan', 'Shahr-e-Ziba', 'Pasdaran', 'Chardivari',
    'Gheitarieh', 'Kamranieh', 'Gholhak', 'Heravi', 'Hashemi', 'Dehkade Olampic', 'Damavand',
    'Republic', 'Zaferanieh', 'Qazvin Imamzadeh Hassan', 'Niavaran', 'Valiasr', 'Qalandari',
    'Amir Bahador', 'Ekhtiarieh', 'Ekbatan', 'Absard', 'Haft Tir', 'Mahallati', 'Ozgol',
    'Tajrish', 'Abazar', 'Koohsar', 'Hekmat', 'Parastar', 'Lavasan', 'Majidieh',
    'Southern Chitgar', 'Karimkhan', 'Si Metri Ji', 'Karoon', 'Northern Chitgar',
    'East Pars', 'Kook', 'Air force', 'Sohanak', 'Komeil', 'Azadshahr', 'Zibadasht',
    'Amirabad', 'Dezashib', 'Elahieh', 'Mirdamad', 'Razi', 'Jordan', 'Mahmoudieh',
    'Shahedshahr', 'Yaftabad', 'Mehran', 'Nasim Shahr', 'Tenant', 'Chardangeh', 'Fallah',
    'Eskandari', 'Shahrakeh Naft', 'Ajudaniye', 'Tehransar', 'Nawab', 'Yousef Abad',
    'Northern Suhrawardi', 'Shahrake Quds', 'Safadasht', 'Khademabad Garden', 'Hassan Abad',
    'Chidz', 'Khavaran', 'Boloorsazi', 'Mehrabad River River', 'Varamin - Beheshti', 'Shoosh',
    'Thirteen November', 'Darakeh', 'Aliabad South', 'Alborz Complex', 'Firoozkooh',
    'Vahidiyeh', 'Shadabad', 'Naziabad', 'Javadiyeh', 'Yakhchiabad'
]

# ===== Matching Persian labels for display (must be same order) =====
address_list_fa = [
    'Ø´Ù‡Ø±Ø§Ù†', 'Ù¾Ø±Ø¯ÛŒØ³', 'Ø´Ù‡Ø±Ú© Ù‚Ø¯Ø³', 'Ø´Ù‡Ø±Ú© ØºØ±Ø¨', 'Ø³Ø§Ø²Ù…Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø´Ù…Ø§Ù„ÛŒ',
    'Ø§Ù†Ø¯ÛŒØ´Ù‡', 'Ø¨Ù„ÙˆØ§Ø± ÙØ±Ø¯ÙˆØ³ ØºØ±Ø¨', 'Ù†Ø§Ø±Ù…Ú©', 'Ø³Ø¹Ø§Ø¯Øª Ø¢Ø¨Ø§Ø¯', 'Ø¸ÙØ±', 'Ø§Ø³Ù„Ø§Ù…Ø´Ù‡Ø±',
    'Ù¾ÛŒØ±ÙˆØ²ÛŒ', 'Ø´Ù‡Ø±Ú© Ø´Ù‡ÛŒØ¯ Ø¨Ø§Ù‚Ø±ÛŒ', 'Ù…Ù†ÛŒØ±ÛŒÙ‡', 'ÙˆÙ„Ù†Ø¬Ú©', 'Ø§Ù…ÛŒØ±ÛŒÙ‡',
    'Ø¬Ù†Øª Ø¢Ø¨Ø§Ø¯ Ø¬Ù†ÙˆØ¨ÛŒ', 'Ø³Ù„Ø³Ø¨ÛŒÙ„', 'Ø²Ø±Ú¯Ù†Ø¯Ù‡', 'Ø¨Ø§Øº ÙÛŒØ¶', 'Ø³Ø§Ø²Ù…Ø§Ù† Ø¢Ø¨',
    'Ù†Ø§Ù…Ø´Ø®Øµ', 'Ø´Ù‡Ø±Ø¢Ø±Ø§', 'Ú¯ÛŒØ´Ø§', 'Ø±ÛŒ', 'Ø¹Ø¨Ø§Ø³ Ø¢Ø¨Ø§Ø¯', 'Ø§Ø³ØªØ§Ø¯ Ù…Ø¹ÛŒÙ†', 'ÙØ±Ù…Ø§Ù†ÛŒÙ‡',
    'Ù¾Ø±Ù†Ø¯', 'Ù¾ÙˆÙ†Ú©', 'Ù‚ØµØ±Ø§Ù„Ø¯Ø´Øª', 'Ø§Ù‚Ø¯Ø³ÛŒÙ‡', 'Ù¾Ø§Ú©Ø¯Ø´Øª', 'Ø±Ø§Ù‡â€ŒØ¢Ù‡Ù†', 'Ø¬Ù†Øª Ø¢Ø¨Ø§Ø¯ Ù…Ø±Ú©Ø²ÛŒ',
    'Ø¨Ù„ÙˆØ§Ø± ÙØ±Ø¯ÙˆØ³ Ø´Ø±Ù‚', 'Ù¾Ø§Ú©Ø¯Ø´Øª Ø®Ø§ØªÙˆÙ†â€ŒØ¢Ø¨Ø§Ø¯', 'Ø³ØªØ§Ø±Ø®Ø§Ù†', 'Ø¨Ø§ØºØ³ØªØ§Ù†', 'Ø´Ù‡Ø±ÛŒØ§Ø±',
    'Ø¬Ù†Øª Ø¢Ø¨Ø§Ø¯ Ø´Ù…Ø§Ù„ÛŒ', 'Ø¯Ø§Ø±ÛŒØ§Ù† Ù†Ùˆ', 'Ø³Ø§Ø²Ù…Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¬Ù†ÙˆØ¨ÛŒ', 'Ø±ÙˆØ¯Ù‡Ù†', 'Ù¾Ø§Ø±Ø³ ØºØ±Ø¨ÛŒ',
    'Ø§ÙØ³Ø±ÛŒÙ‡', 'Ù…Ø±Ø²Ø¯Ø§Ø±Ø§Ù†', 'Ø¯Ø±ÙˆØ³', 'ØµØ§Ø¯Ù‚ÛŒÙ‡', 'Ú†Ù‡Ø§Ø±Ø¯Ø§Ù†Ú¯Ù‡', 'Ø¨Ø§Ù‚Ø±Ø´Ù‡Ø±', 'Ø¬ÛŒ',
    'Ù„ÙˆÛŒØ²Ø§Ù†', 'Ø´Ù…Ø³â€ŒØ¢Ø¨Ø§Ø¯', 'ÙØ§Ø·Ù…ÛŒ', 'Ø¨Ù„ÙˆØ§Ø± Ú©Ø´Ø§ÙˆØ±Ø²', 'Ú©Ù‡Ø±ÛŒØ²Ú©', 'Ù‚Ø±Ú†Ú©',
    'Ø¬Ù…Ø§Ù„Ø²Ø§Ø¯Ù‡ Ø´Ù…Ø§Ù„ÛŒ', 'Ø¢Ø°Ø±Ø¨Ø§ÛŒØ¬Ø§Ù†', 'Ø¨Ù‡Ø§Ø±', 'Ø¯Ø±ÛŒØ§Ú†Ù‡ Ø´Ù‡Ø¯Ø§ÛŒ Ø®Ù„ÛŒØ¬ ÙØ§Ø±Ø³', 'Ø¨Ø±ÛŒØ§Ù†Ú©',
    'Ù‡Ø´Ù…ØªÛŒÙ‡', 'Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª', 'Ú¯Ù„Ø³ØªØ§Ù†', 'Ø´Ù‡Ø± Ø²ÛŒØ¨Ø§', 'Ù¾Ø§Ø³Ø¯Ø§Ø±Ø§Ù†', 'Ú†Ø§Ø±Ø¯ÛŒÙˆØ§Ø±ÛŒ',
    'Ù‚ÛŒØ·Ø±ÛŒÙ‡', 'Ú©Ø§Ù…Ø±Ø§Ù†ÛŒÙ‡', 'Ù‚Ù„Ù‡Ú©', 'Ù‡Ø±ÙˆÛŒ', 'Ù‡Ø§Ø´Ù…ÛŒ', 'Ø¯Ù‡Ú©Ø¯Ù‡ Ø§Ù„Ù…Ù¾ÛŒÚ©', 'Ø¯Ù…Ø§ÙˆÙ†Ø¯',
    'Ø¬Ù…Ù‡ÙˆØ±ÛŒ', 'Ø²Ø¹ÙØ±Ø§Ù†ÛŒÙ‡', 'Ù‚Ø²ÙˆÛŒÙ† Ø§Ù…Ø§Ù…Ø²Ø§Ø¯Ù‡ Ø­Ø³Ù†', 'Ù†ÛŒØ§ÙˆØ±Ø§Ù†', 'ÙˆÙ„ÛŒØ¹ØµØ±', 'Ù‚Ù„Ù†Ø¯Ø±ÛŒ',
    'Ø§Ù…ÛŒØ± Ø¨Ù‡Ø§Ø¯Ø±', 'Ø§Ø®ØªÛŒØ§Ø±ÛŒÙ‡', 'Ø§Ú©Ø¨Ø§ØªØ§Ù†', 'Ø¢Ø¨Ø³Ø±Ø¯', 'Ù‡ÙØª ØªÛŒØ±', 'Ù…Ø­Ù„Ø§ØªÛŒ', 'Ø§ÙˆØ¬Ú¯Ù„',
    'ØªØ¬Ø±ÛŒØ´', 'Ø¢Ø°Ø±Ø¢Ø²', 'Ú©ÙˆÙ‡Ø³Ø§Ø±', 'Ø­Ú©Ù…Øª', 'Ù¾Ø±Ø³ØªØ§Ø±', 'Ù„ÙˆØ§Ø³Ø§Ù†', 'Ù…Ø¬ÛŒØ¯ÛŒÙ‡',
    'Ú†ÛŒØªÚ¯Ø± Ø¬Ù†ÙˆØ¨ÛŒ', 'Ú©Ø±ÛŒÙ…Ø®Ø§Ù†', 'Ø³ÛŒâ€ŒÙ…ØªØ±ÛŒ Ø¬ÛŒ', 'Ú©Ø§Ø±ÙˆÙ†', 'Ú†ÛŒØªÚ¯Ø± Ø´Ù…Ø§Ù„ÛŒ',
    'Ù¾Ø§Ø±Ø³ Ø´Ø±Ù‚ÛŒ', 'Ú©ÙˆÚ©', 'Ù†ÛŒØ±ÙˆÛŒ Ù‡ÙˆØ§ÛŒÛŒ', 'Ø³ÙˆÙ‡Ø§Ù†Ú©', 'Ú©Ù…ÛŒÙ„', 'Ø¢Ø²Ø§Ø¯Ø´Ù‡Ø±', 'Ø²ÛŒØ¨Ø§Ø¯Ø´Øª',
    'Ø§Ù…ÛŒØ±Ø¢Ø¨Ø§Ø¯', 'Ø¯Ø²Ø§Ø´ÛŒØ¨', 'Ø§Ù„Ù‡ÛŒÙ‡', 'Ù…ÛŒØ±Ø¯Ø§Ù…Ø§Ø¯', 'Ø±Ø§Ø²ÛŒ', 'Ø¬Ø±Ø¯Ù†', 'Ù…Ø­Ù…ÙˆØ¯ÛŒÙ‡',
    'Ø´Ø§Ù‡Ø¯Ø´Ù‡Ø±', 'ÛŒØ§ÙØªâ€ŒØ¢Ø¨Ø§Ø¯', 'Ù…Ù‡Ø±Ø§Ù†', 'Ù†Ø³ÛŒÙ…â€ŒØ´Ù‡Ø±', 'Ù…Ø³ØªØ§Ø¬Ø±', 'ÙÙ„Ø§Ø­',
    'Ø§Ø³Ú©Ù†Ø¯Ø±ÛŒ', 'Ø´Ù‡Ø±Ú© Ù†ÙØª', 'Ø§Ø¬ÙˆØ¯Ø§Ù†ÛŒÙ‡', 'ØªÙ‡Ø±Ø§Ù†Ø³Ø±', 'Ù†ÙˆØ§Ø¨', 'ÛŒÙˆØ³Ùâ€ŒØ¢Ø¨Ø§Ø¯',
    'Ø³Ù‡Ø±ÙˆØ±Ø¯ÛŒ Ø´Ù…Ø§Ù„ÛŒ', 'Ø´Ù‡Ø±Ú© Ù‚Ø¯Ø³', 'ØµÙØ§Ø¯Ø´Øª', 'Ø¨Ø§Øº Ø®Ø§Ø¯Ù…â€ŒØ¢Ø¨Ø§Ø¯', 'Ø­Ø³Ù†â€ŒØ¢Ø¨Ø§Ø¯',
    'Ú†ÛŒØ°Ø±', 'Ø®Ø§ÙˆØ±Ø§Ù†', 'Ø¨Ù„ÙˆØ±Ø³Ø§Ø²ÛŒ', 'Ø±ÙˆØ¯Ø®Ø§Ù†Ù‡ Ù…Ù‡Ø±Ø¢Ø¨Ø§Ø¯', 'ÙˆØ±Ø§Ù…ÛŒÙ† - Ø¨Ù‡Ø´ØªÛŒ', 'Ø´ÙˆØ´',
    'Ø³ÛŒØ²Ø¯Ù‡ Ø¢Ø¨Ø§Ù†', 'Ø¯Ø±Ø¨Ù†Ø¯', 'Ø¹Ù„ÛŒâ€ŒØ¢Ø¨Ø§Ø¯ Ø¬Ù†ÙˆØ¨ÛŒ', 'Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ø¨Ø±Ø²', 'ÙÛŒØ±ÙˆØ²Ú©ÙˆÙ‡',
    'ÙˆØ­ÛŒØ¯ÛŒÙ‡', 'Ø´Ø§Ø¯Ø¢Ø¨Ø§Ø¯', 'Ù†Ø§Ø²ÛŒâ€ŒØ¢Ø¨Ø§Ø¯', 'Ø¬ÙˆØ§Ø¯ÛŒÙ‡', 'ÛŒØ§Ø®Ú†ÛŒâ€ŒØ¢Ø¨Ø§Ø¯'
]

# create mapping (eng -> fa)
eng_to_fa = dict(zip(address_list_eng, address_list_fa))

# ===== Styling RTL =====
st.markdown("""
    <style>
        .main { direction: rtl; }
        .stSelectbox > div { direction: rtl; }  /* try to help selectbox direction */
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ  Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø®Ø§Ù†Ù‡ Ø¯Ø± ØªÙ‡Ø±Ø§Ù†")

# ===== Inputs: area/room defaults & inline checkboxes =====
col1, col2 = st.columns(2)
with col1:
    area = st.number_input("Ù…ØªØ±Ø§Ú˜ (Ù…ØªØ± Ù…Ø±Ø¨Ø¹)", min_value=1, step=1, value=50)
with col2:
    room = st.number_input("ØªØ¹Ø¯Ø§Ø¯ Ø§ØªØ§Ù‚", min_value=1, step=1, value=2)

chk1, chk2, chk3 = st.columns(3)
with chk1:
    parking = 1 if st.checkbox("Ù¾Ø§Ø±Ú©ÛŒÙ†Ú¯") else 0
with chk2:
    warehouse = 1 if st.checkbox("Ø§Ù†Ø¨Ø§Ø±ÛŒ") else 0
with chk3:
    elevator = 1 if st.checkbox("Ø¢Ø³Ø§Ù†Ø³ÙˆØ±") else 0

# ===== Address selectbox: options are EN keys, but show Persian labels =====
address_eng = st.selectbox(
    "Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø­Ù„Ù‡",
    options=address_list_eng,
    format_func=lambda x: "\u200F" + eng_to_fa.get(x, x)  # \u200F = RIGHT-TO-LEFT MARK Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ØµØ­ÛŒØ­
)

# ===== Map: show Persian labels in tooltip (filter out missing coords) =====
map_points = []
for eng in address_list_eng:
    lat, lon = coords.get(eng, (None, None))
    if lat is not None and lon is not None:
        map_points.append({
            "lat": lat,
            "lon": lon,
            "label": eng_to_fa.get(eng, eng)
        })

if map_points:
    df_map = pd.DataFrame(map_points)
    layer = pdk.Layer(
        "ScatterplotLayer",
        data=df_map,
        get_position=["lon", "lat"],
        get_fill_color=[75, 0, 130],
        get_radius=100,
        pickable=True
    )
    
tooltip = {
    "html": """
        <div style='
            direction: rtl;
            text-align: right;
            font-weight: 600;
            font-family: Vazirmatn, sans-serif;
            white-space: nowrap;
        '>{label}</div>
    """,
    "style": {"backgroundColor": "white"}
}

    
map_points.append({
    "lat": lat,
    "lon": lon,
    "label": eng_to_fa.get(eng, eng)  # Convert to Persian for display
})
    
coords_df = pd.DataFrame({
    "lat": [coords.get(addr, (None, None))[0] for addr in address_list_eng if coords.get(addr, (None, None))[0] is not None],
    "lon": [coords.get(addr, (None, None))[1] for addr in address_list_eng if coords.get(addr, (None, None))[1] is not None],
})
if not coords_df.empty:
    st.markdown("Ù†Ù‚Ø´Ù‡â€ŒÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ ğŸ—º")
    st.map(coords_df)

# ===== Prepare features (use eng key for Address so it matches model) =====
latitude, longitude = coords.get(address_eng, (None, None))
area_per_room = area / room if room else 0
total_facilities = parking + warehouse + elevator
address_freq_val = address_freq.get(address_eng, 0)

input_df = pd.DataFrame({
    "Area": [area],
    "Room": [room],
    "Parking": [parking],
    "Warehouse": [warehouse],
    "Elevator": [elevator],
    "Address": [address_eng],   # <-- ENGLISH key, matches training
    "Area_per_Room": [area_per_room],
    "Total_Facilities": [total_facilities],
    "Address_Freq": [address_freq_val],
    "Latitude": [latitude],
    "Longitude": [longitude],
})

# ===== Predict =====
if st.button("ğŸ’° Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª"):
    pred = model.predict(input_df)[0] * 98000
    st.success(f"ğŸ’µ Ù‚ÛŒÙ…Øª ØªÙ‚Ø±ÛŒØ¨ÛŒ: {pred:,.0f} ØªÙˆÙ…Ø§Ù†")

